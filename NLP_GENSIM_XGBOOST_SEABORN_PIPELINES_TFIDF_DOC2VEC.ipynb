{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/towards-artificial-intelligence/text-classification-by-xgboost-others-a-case-study-using-bbc-news-articles-5d88e94a9f8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bbc_text_df = pd.read_csv('data/bbc-text.csv')\n",
    "bbc_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(x=bbc_text_df.category, color='green')\n",
    "plt.title('BBC text class distribution', fontsize=16)\n",
    "plt.ylabel('Class Counts', fontsize=16)\n",
    "plt.xlabel('Class Label', fontsize=16)\n",
    "plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requierments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "filters = [\n",
    "           gsp.strip_tags, \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric,\n",
    "           gsp.remove_stopwords, \n",
    "           gsp.strip_short, \n",
    "           gsp.stem_text\n",
    "          ]\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_text_df.iloc[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(bbc_text_df.iloc[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def plot_word_cloud(text):\n",
    "    wordcloud_instance = WordCloud(width = 800, height = 800, \n",
    "                background_color ='black', \n",
    "                stopwords=None,\n",
    "                min_font_size = 10).generate(text) \n",
    "             \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud_instance) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ''\n",
    "for index, item in bbc_text_df.iterrows():\n",
    "    texts = texts + ' ' + clean_text(item['text'])\n",
    "    \n",
    "plot_word_cloud(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_cloud_for_category(bbc_text_df, category):\n",
    "    text_df = bbc_text_df.loc[bbc_text_df['category'] == str(category)]\n",
    "    texts = ''\n",
    "    for index, item in text_df.iterrows():\n",
    "        texts = texts + ' ' + clean_text(item['text'])\n",
    "    \n",
    "    plot_word_cloud(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud_for_category(bbc_text_df,'tech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_cloud_for_category(bbc_text_df,'sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = bbc_text_df['text']\n",
    "df_y = bbc_text_df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import utils as skl_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator):\n",
    "\n",
    "    def __init__(self, vector_size=100, learning_rate=0.02, epochs=20):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self._model = None\n",
    "        self.vector_size = vector_size\n",
    "        self.workers = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    def fit(self, df_x, df_y=None):\n",
    "        tagged_x = [TaggedDocument(clean_text(row).split(), [index]) for index, row in enumerate(df_x)]\n",
    "        model = Doc2Vec(documents=tagged_x, vector_size=self.vector_size, workers=self.workers)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            model.train(skl_utils.shuffle([x for x in tqdm(tagged_x)]), total_examples=len(tagged_x), epochs=1)\n",
    "            model.alpha -= self.learning_rate\n",
    "            model.min_alpha = model.alpha\n",
    "\n",
    "        self._model = model\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_x):\n",
    "        return np.asmatrix(np.array([self._model.infer_vector(clean_text(row).split())\n",
    "                                     for index, row in enumerate(df_x)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_trf = Doc2VecTransformer()\n",
    "doc2vec_features = doc2vec_trf.fit(df_x).transform(df_x)\n",
    "doc2vec_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pl_log_reg = Pipeline(steps=[('doc2vec',Doc2VecTransformer()),\n",
    "                             ('log_reg', LogisticRegression(multi_class='multinomial', solver='saga', max_iter=100))])\n",
    "scores = cross_val_score(pl_log_reg, df_x, df_y, cv=5,scoring='accuracy')\n",
    "print('Accuracy for Logistic Regression: ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "pl_xgb = Pipeline(steps=[('doc2vec',Doc2VecTransformer()),\n",
    "                         ('xgboost', xgb.XGBClassifier(objective='multi:softmax'))])\n",
    "scores = cross_val_score(pl_xgb, df_x, df_y, cv=5)\n",
    "print('Accuracy for XGBoost Classifier : ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pl_random_forest = Pipeline(steps=[('doc2vec',Doc2VecTransformer()),\n",
    "                                   ('random_forest', RandomForestClassifier())])\n",
    "scores = cross_val_score(pl_random_forest, df_x, df_y, cv=5,scoring='accuracy')\n",
    "print('Accuracy for RandomForest : ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class Text2TfIdfTransformer(BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._model = TfidfVectorizer()\n",
    "        pass\n",
    "\n",
    "    def fit(self, df_x, df_y=None):\n",
    "        df_x = df_x.apply(lambda x : clean_text(x))\n",
    "        self._model.fit(df_x)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_x):\n",
    "        return self._model.transform(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = Text2TfIdfTransformer()\n",
    "tfidf_vectors = tfidf_transformer.fit(df_x).transform(df_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_log_reg_tf_idf = Pipeline(steps=[('tfidf',Text2TfIdfTransformer()),\n",
    "                             ('log_reg', LogisticRegression(multi_class='multinomial', solver='saga', max_iter=100))])\n",
    "scores = cross_val_score(pl_log_reg_tf_idf, df_x, df_y, cv=5,scoring='accuracy')\n",
    "print('Accuracy for Tf-Idf & Logistic Regression: ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_random_forest_tf_idf = Pipeline(steps=[('tfidf',Text2TfIdfTransformer()),\n",
    "                                   ('random_forest', RandomForestClassifier())])\n",
    "scores = cross_val_score(pl_random_forest_tf_idf, df_x, df_y, cv=5,scoring='accuracy')\n",
    "print('Accuracy for Tf-Idf & RandomForest : ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_xgb_tf_idf = Pipeline(steps=[('tfidf',Text2TfIdfTransformer()),\n",
    "                         ('xgboost', xgb.XGBClassifier(objective='multi:softmax'))])\n",
    "scores = cross_val_score(pl_xgb_tf_idf, df_x, df_y, cv=5)\n",
    "print('Accuracy for Tf-Idf & XGBoost Classifier : ', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
